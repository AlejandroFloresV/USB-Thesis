\chapter{Metaheurísticas}
\label{capitulo2}
\lhead{Capítulo 2. \emph{Metaheurísticas}}

\section{Descripción general}

Las metaheurísticas son métodos estocásticos de búsqueda de propósito general sobre espacios combinatorios. Son usados generalmente para tratar problemas de optimización combinatoria, donde su complejidad hace imposible evaluar todas las soluciones factibles en un tiempo razonable; estos algoritmos son capaces de conseguir ``buenas'' soluciones a un problema en un período de tiempo mucho menor. Sin embargo, para muchos problemas la complejidad de estos algoritmos sigue siendo un factor prohíbitivo, debido al uso de funciones ``costosas'' para la evaluación de soluciones intermedias (\emph{fitness}).

La idea es desarrollar algoritmos que recorran solo una fracción del espacio de soluciones, y que sean capaces de encontrar soluciones óptimas o casi óptimas al problema en cuestión. Para lograrlo, las metaheurísticas combinan procesos de \emph{diversificación} e \emph{intensificación} (o \emph{exploración} y \emph{explotación} respectivamente) \cite{Yang:2008:NMA:1628847}. La fase de \emph{diversificación} implica la generación de soluciones diversas con el objeto de explorar el espacio de búsqueda, mientras que la fase de \emph{intensificación} se refiere al mejoramiento de soluciones (conseguir óptimos locales) mediante el uso de métodos de búsqueda local. La selección de las mejores soluciones asegura la convergencia a soluciones óptimas, mientras que la exploración aleatoria de soluciones evita que el algoritmo quede ``atrapado'' en óptimos locales. La combinación en el uso de ambos procesos hace posible conseguir buenas soluciones al problema sin la necesidad de recorrer el espacio de búsqueda completo.

Cada metaheurística está caracterizada por las estratégias que usa para cada fase, así como el orden y la frecuencia en que las aplica; esto permite clasificarlas en función de su similitud. En este sentido, a continuación se describe un conjunto de metaheurísticas caracterizadas por tener a la naturaleza como fuente de inspiración.

\section{Metaheurísticas inspiradas en la naturaleza}

La habilidad de la naturaleza para moldear soluciones a situaciones complejas, mediante procesos y reglas caracterizadas por su simplicidad, la ha convertido en una fuente inagorable de inspiración para el desarrollo de algoritmos de optimización. Estos algoritmos a menudo presentan buen desempeño para aproximar soluciones a todo tipo de problemas, dado que no requieren información sobre la distrubución del espacio de búsqueda. Por esta razón, existe una amplia literatura sobre enfoques bio-inspirados \cite{binitha2012survey} para resolver gran variedad de problemas en diversas áreas de computación.

En particular, los enfoques más comunes en la literatura sobre metaheurísticas inspiradas en la naturaleza se apoyan en
\begin{inparaenum}[\itshape a\upshape)]
\item la evolución de poblaciones (Algoritmos Evolutivos) y
\item el comportamiento colectivo (Inteligencia de Enjambre).
\end{inparaenum}

\subsection{Algoritmos Evolutivos}

Los Algoritmos Evolutivos (\emph{AE}) son metaheurísticas basadas en procesos de evolución biológica con el objetivo de explorar en amplitud espacios de solución con distribución desconocida. Con el fin de replicar los procesos evolutivos, los \emph{AE} mantienen un conjunto de soluciones candidatas al problema (una \emph{población} de \emph{cromosomas}/\emph{individuos}), que modifican iterativamente apoyandose en el uso de operadores de \emph{mutación}, \emph{recombinación} y/o \emph{selección}.

Los \emph{AE} codifican cada cromosoma como una cadena de genes de tamaño $l$ (análogo a la estructura del ADN), donde cada gen representa una parte de la solución al problema en cuestión. A partir de esta representación, los \emph{AE} definen un conjunto de operadores que cumplen la función de las estrategias de \emph{exploración} y \emph{explotación}:

\begin{itemize}
\item \emph{Mutación}: Modifica los genes de soluciones intermedias con la finalidad de explorar el espacio de soluciones e introducir nueva información a la población. Simula la variabilidad en las poblaciones, fenómeno clave para la aparición de nuevos genes que aumenten la posibilidad de supervivencia.
\item \emph{Recombinación}/\emph{Crossover}: Permite el intercambio de información entre individuos de la población. Simula la reproducción entre individuos, necesaria para la transmisión de genes relevantes a las siguientes generaciones.
\item \emph{Selección}: Las estrategias de selección permiten definir aquellos individuos que participarán en la fase de reproducción, y por ende los genes que pasarán a la siguiente generación. Esto simula el proceso de selección natural en el que sobreviven los individuos mejor adaptados al ambiente.
\end{itemize}

En la literatura se han desarrollado diferentes esquemas que definen el uso de estos operadores. Los \emph{AE} más ``tradicionales'' son conocidos como \emph{Algoritmos Genéticos} (\emph{AG}) \cite{holland1975adaptation}, que suponen la aplicación más directa de los conceptos del proceso evolutivo. Sin embargo, dentro de la clase de \emph{AE} existe otro grupo de algoritmos que aplican dichos conceptos de forma diferente; la clase de \emph{Algorítmos de Estimación de Distribución} (``\emph{Estimation of Distribution Algorithm}'' - EDA) aplican los operadores de \emph{mutación}, \emph{recombinación} y \emph{selección} sobre una población de soluciones implicita en un modelo de distribución probabilístico.

A continuación se describen cuatro algoritmos pertenecientes a la clase de \emph{AE}: GGA, SGA y CHC, variantes del grupo de \emph{AG}, y PBIL, perteneciente a los \emph{EDA}.

\subsubsection{Generational Genetic Algorithm (GGA)}

GGA es el esquema ``tradicional'' de aplicación de los \emph{AG} \cite{back1996evolutionary,Muhlenbein91evolutionin}. Mantiene una población de individuos que evolucionan durante un número de iteraciones. Su principal característica es que en cada iteración se genera una nueva población, \emph{i.e.} un proceso de evolución \emph{generacional}.

En cada iteración el proceso evolutivo consiste en la creación de una nueva población de tamaño $\texttt{pop}$ mediante:
\begin{inparaenum}[\itshape a\upshape)]
\item la selección de los individuos para el proceso de reproducción (\emph{padres}),
\item la recombinación (con probabilidad $\texttt{cp}$) de pares de individuos \emph{padres} usando una estrategia particular de cruce/\emph{crossover}, y
\item la mutación de los individuos de la nueva población (llamados \emph{descendencia}), usando una probabilidad de mutación de cada gen igual a $\texttt{mp}$.
\end{inparaenum}
Ver el algoritmo \ref{gga-alg}.

\begin{algorithm}
\caption{Generational Genetic Algorithm}
\label{gga-alg}
\begin{algorithmic}[1]

\Require{\texttt{pop} tamaño de la población,
	\texttt{cp} probabilidad de cruce,
	\texttt{mp} probabilidad de mutación}
\Ensure{Una solución al problema}

\State $P \gets$ Generar población aleatoria de $\texttt{pop}$ individuos
\State $s^* \gets $ el \emph{mejor} individuo en $P$
\While{$\neg$ Condición de parada}
	\State $P' \gets \emptyset$
	\While{$\mid P' \mid < \texttt{pop}$}
		\State $p_1 \gets$ Seleccionar un individuo en $P$
		\State $p_2 \gets$ Seleccionar un individuo en $P$
		\State $c_1, c_2 \gets $ recombinar $p_1$ y $p_2$ con probabilidad $\texttt{cp}$
		\State Mutar $c_1$ y $c_2$ con probabilidad $\texttt{mp}$
		\State $P' \gets P' \cup \left\lbrace c_1, c_2 \right\rbrace$
	\EndWhile
	\State $P \gets P'$
	\If{El \emph{mejor} individuo en $P$ es \emph{mejor} que $s^*$}
		\State $s^* \gets$ el \emph{mejor} individuo en $P$
	\EndIf
\EndWhile
\State \Return $s^*$

\end{algorithmic}
\end{algorithm}

\subsubsection{Steady-State Genetic Algorithm (SGA)}

Descrito por \emph{Whitley et al.} \cite{whitley1988genitor}, SGA es una modificación del esquema general de \emph{AG} que sigue una estrategia reproductiva no generacional. SGA comienza con una población de tamaño $\texttt{pop}$, y en cada iteración se producen un máximo de dos nuevos individuos (no una nueva población).

En cada iteración
\begin{inparaenum}[\itshape a\upshape)]
\item se seleccionan dos individuos padres de la población actual,
\item se crea su descendencia (con probabilidad $\texttt{cp}$) mediante algún metodo de cruce/recombinación,
\item se agrega variabilidad mediante la mutación (con probabilidad $\texttt{mp}$) de la nueva descendencia, y
\item se sigue alguna estrategia de selección para reemplazar individuos en la población por la nueva descendencia, y así mantener el tamaño de la población igual a $\texttt{pop}$.
\end{inparaenum}
Ver el algoritmo \ref{sga-alg}.

\begin{algorithm}
\caption{Steady-State Genetic Algorithm}
\label{sga-alg}
\begin{algorithmic}[1]

\Require{\texttt{pop} tamaño de la población,
	\texttt{cp} probabilidad de cruce,
	\texttt{mp} probabilidad de mutación}
\Ensure{Una solución al problema}

\State $P \gets$ Generar población aleatoria de $\texttt{pop}$ individuos
\State $s^* \gets $ el \emph{mejor} individuo en $P$
\While{$\neg$ Condición de parada}
	\State $p_1 \gets$ Seleccionar un individuo en $P$
	\State $p_2 \gets$ Seleccionar un individuo en $P$
	\State $c_1, c_2 \gets $ recombinar $p_1$ y $p_2$ con probabilidad $\texttt{cp}$
	\State Mutar $c_1$ y $c_2$ con probabilidad $\texttt{mp}$
	\State Seguir algún criterio de reemplazo de individuos en $P$ por $c_1$ y $c_2$
	\If{El \emph{mejor} individuo en $P$ es \emph{mejor} que $s^*$}
		\State $s^* \gets$ el \emph{mejor} individuo en $P$
	\EndIf
\EndWhile
\State \Return $s^*$

\end{algorithmic}
\end{algorithm}

\subsubsection{CHC Adaptive Search Algorithm}

CHC \cite{eshelman1990chc} se basa en el esquema de evolución generacional aplicado por GGA; mantiene una población de individuos de tamaño fijo ($\texttt{pop}$), generando una nueva población en cada iteración. Sin embargo, en cada iteración CHC aplica una estrategia de reemplazo ``elitista'', donde sobreviven los mejores individuos entre la población actual y la descendencia producida.

La fase de reproducción aplicada por CHC tiene dos particularidades. En primer lugar, implementa un operador de recombinación uniforme media llamado HUX (``\emph{Half Uniform Crossover}''), que intercambia la mitad de los genes que difieren entre los dos padres de forma aleatoria. Adicionalmente, CHC emplea ``prevención de incesto'': antes de realizar el cruce usando HUX, calcula la \emph{distancia de Hamming} entre ambos padres; si dicha distancia es mayor a cierto umbral (inicialmente $l/4$, donde $l$ es la longitud de los cromosomas), se realiza el cruce. En caso de no generarse ninguna descendencia durante una iteración particular, se disminuye el umbral en 1.

Durante el proceso de evolución de CHC no se aplica el operador de mutación: cuando el umbral de prevención de incesto llega a cero se considera que la población convergió, y comienza un proceso de repoblación en el que se usa la mejor solución encontrada hasta el momento. Se modifican hasta $35\%$ de sus genes de forma aleatoria para generar los $\texttt{pop}-1$ individuos restantes de la nueva población, y luego continuar el proceso evolutivo.

A continuación se presenta el pseudocódigo para CHC (algoritmo \ref{chc-alg}).

\begin{algorithm}
\caption{CHC Adaptive Search Algorithm}
\label{chc-alg}
\begin{algorithmic}[1]

\Require \texttt{pop} tamaño de la población
\Ensure Una solución al problema

\State $P \gets$ Generar población aleatoria de $\texttt{pop}$ individuos
\State $s^* \gets $ el \emph{mejor} individuo en $P$
\State $\mu \gets l/4$ \Comment Umbral de cruce
\While {$\neg$ Condición de parada}
	\For {$i \in [1 \dots \texttt{pop}/2]$}
		\State $p_1 \gets$ Seleccionar un individuo en $P$
		\State $p_2 \gets$ Seleccionar un individuo en $P$
		\If {$hamming(p_1,p_2) > \mu$}
			\State $c_1, c_2 \gets $ recombinar $p_1$ y $p_2$ usando HUX
			\State $P \gets P \cup \left\lbrace c_1, c_2 \right\rbrace$
		\EndIf
	\EndFor
	\If {$\mid P \mid = \texttt{pop}$}
		\State $\mu \gets \mu-1$
		\If {$\mu = 0$}
			\State $P \gets$ Generar población de $\texttt{pop}$ individuos usando $s^*$
			\State $\mu \gets l/4$
		\EndIf
	\Else
		\State $P \gets \texttt{pop}$ mejores individuos en $P$
		\If {El \emph{mejor} individuo en $P$ es \emph{mejor} que $s^*$}
			\State $s^* \gets$ el \emph{mejor} individuo en $P$
		\EndIf
	\EndIf
\EndWhile
\State \Return $s^*$

\end{algorithmic}
\end{algorithm}

\subsubsection{Population-Based Incremental Learning (PBIL)}

PBIL es una metaheurística perteneciente a la clase de \emph{Algoritmos de Estimación de Distribución} desarrollada por \emph{Baluja} \cite{Baluja94pbil} para su uso sobre cromosomas con representación binaria. PBIL destaca por ser más simple que los algoritmos genéticos tradicionales y por lograr mejores soluciones para gran variedad de problemas \cite{Baluja95anempirical,Baluja95removingthe}.

Este algoritmo mantiene una población \emph{implicita} de soluciones, mediante el uso de un vector de probabilidades $V$ de tamaño $l$, donde $V_i$ (con $i \in [1 \dots l]$) es la probabilidad que el $i$-esimo bit/gen de una solución en la población esté ``prendido'' (sea igual a 1). PBIL usa este vector de probabilidades para generar poblaciones de tamaño $\texttt{pop}$ en cada iteración, y guiar el proceso evolutivo en base a las soluciones generadas.

Inicialmente $V_i = 0.5\ \ \forall{i \in [1\dots l]}$. Luego en cada iteración:
\begin{inparaenum}[\itshape a\upshape)]
\item se generan $\texttt{pop}$ cromosomas binarios basados en las probabilidades en $V$,
\item se ``acerca'' $V$ hacia la mejor solución generada (usando una tasa de aprendizaje $\texttt{lr}$), 
\item se ``aleja'' $V$ de la peor solución generada (usando una tasa de aprendizaje negativa $\texttt{nlr}$),
\item se sigue una estrategia de mutación sobre $V$ en la que se aumenta o disminuye $V_i$ en $\texttt{ms}$ (\emph{mutation shift}) con probabilidad de mutación $\texttt{mp}$.
\end{inparaenum}
Ver algoritmo \ref{pbil-alg}.

\begin{algorithm}
\caption{Population-Based Incremental Learning}
\label{pbil-alg}
\begin{algorithmic}[1]

\Require \texttt{pop} tamaño de la población,
	\texttt{mp} probabilidad de mutación,
	\texttt{ms} mutation shift,
	\texttt{lr} learning rate,
	\texttt{nlr} negative learning rate
\Ensure Una solución al problema

\State $V \gets$ Vector de probabilidades de tamaño $l$
\State $s^* \gets$ Una solución cualquiera
\While {$\neg$ Condición de parada}
	\State $P \gets$ Generar población de tamaño $\texttt{pop}$ según las probabilidades en $V$
	\State $b \gets $ El \emph{mejor} individuo en $P$
	\State $w \gets $ El \emph{peor} individuo en $P$
	\If {$b$ es \emph{mejor} que $s^*$}
		\State $s^* \gets b$
	\EndIf
	\For {$i \in [1 \dots l]$} \Comment{Actualizar el vector de probabilidades}
		\State $V_i \gets V_i * (1 - \texttt{lr}) + b_i * \texttt{lr}$
		\If {$b_i \neq w_i$}
			\State $V_i \gets V_i * (1 - \texttt{nlr}) + b_i * \texttt{nlr}$
		\EndIf
		\If {$\mathrm{Unif}(0,1) < \texttt{mp}$} \Comment{Mutación con probabilidad $\texttt{mp}$}
			\State $V_i \gets V_i * (1 - \texttt{ms}) + \mathrm{UnifDiscreta}(0,1) * \texttt{ms}$
		\EndIf
	\EndFor
\EndWhile
\State \Return $s^*$

\end{algorithmic}
\end{algorithm}

\subsection{Inteligencia de Enjambre}

\emph{Inteligencia de Enjambre} \cite{Bonabeau:1999:SIN:328320} (\emph{IE}) es un paradigma emergente entre los sistemas de cómputo bio-inspirados; surge como una extensión de los \emph{AE}, pero no se basa en la adaptación genética de poblaciones, sino en el comportamiento colectivo de grupos de organismos. Las estrategias de \emph{IE} exhiben patrones de búsqueda descentralizada y auto-organizada, mediante la simulación de la inteligencia colectiva de grupos de ``agentes'' sencillos.

Durante la última década se han desarrollado numerosos enfoques basados en la explotación de inteligencia colectiva; inspirados en el comportamiendo de colonias de hormigas, abejas, luciérnagas, etc. Uno de los más estudiados se conoce como PSO, inspirado en el vuelo de grupos de aves.

\subsubsection{Particle Swarm Optimization (PSO)}

PSO \cite{kennedy1995particle} se inspira en el comportamiento de organismos biológicos, en particular del vuelo de bandadas. Cada ave o ``partícula'' representa una solución que se mueve en el espacio de soluciones del problema, y modifica su ``vuelo'' en relación a su propia experiencia y la de sus ``compañeras''. Diferentes estudios \cite{shi1998modified,kennedy1998matching} muestran que PSO obtiene mejores resultados que los algoritmos genéticos y en menor tiempo de cómputo.

La $i$-esima partícula de PSO tiene asociado
\begin{inparaenum}[\itshape a\upshape)]
\item un vector de posición $x_i \in \mathbb{R}^l$ en un espacio euclideano $l$-dimensional que representa una solución al problema (\emph{i.e.} un cromosoma de tamaño $l$ con genes en pertenecientes a $\mathbb{R}$), y
\item un vector de velocidad $v_i \in \mathbb{R}^l$ que modifica la posición de la partícula en cada iteración.
\end{inparaenum}
Ver algoritmo \ref{pso-alg}.

\begin{algorithm}
\caption{Particle Swarm Optimization}
\label{pso-alg}
\begin{algorithmic}[1]

\Require \texttt{part} número de particulas,
	\texttt{vmax} velocidad máxima,
	\texttt{w} peso de inercia,
	\texttt{c1} peso del mejor local,
	\texttt{c2} peso del mejor global
\Ensure Una solución al problema

\For{$i \in [1 \dots \texttt{part}]$}
	\State{$\vec{X_i} \gets$ Solución inicial aleatoria $\in \mathbb{R}^l$}
	\State{$\vec{V_i} \gets$ Vector de velocidades aleatorias entre $[-\texttt{vmax},\texttt{vmax}]$}
	\State{$p_i \gets \vec{X_i}$} \Comment{La \emph{mejor} solución encontrada por la particula $i$}
\EndFor
\State $s^* \gets$ La \emph{mejor} solución $p_i, i \in [1 \dots \texttt{part}]$
\While {$\neg$ Condición de parada}
	\For{$i \in [1 \dots \texttt{part}]$}
		\State{$\vec{X_i} \gets \vec{X_i} + \vec{V_i}$}
		\State{$\vec{V_i} \gets \texttt{w} \vec{V_i} + \texttt{c1}\ \mathrm{Unif}(0,1) (p_i - \vec{X_i}) + \texttt{c2}\ \mathrm{Unif}(0,1) (s^* - \vec{X_i})$}
		\State{Limitar valores en $\vec{V_i}$ entre $[-\texttt{vmax},\texttt{vmax}]$}
		\If {$\vec{X_i}$ es \emph{mejor} que $p_i$}
			\State $p_i \gets \vec{X_i}$
			\If {$p_i$ es \emph{mejor} que $s^*$}
				\State $s^* \gets p_i$
			\EndIf
		\EndIf
	\EndFor
\EndWhile
\State \Return $s^*$

\end{algorithmic}
\end{algorithm}

El vector de velocidad se modifica en función de varios parámetros:
\begin{inparaenum}[\itshape a\upshape)]
\item el peso de inercia $\texttt{w} \in \mathbb{R}$ que evita cambios bruscos respecto a la velocidad anterior,
\item el peso del mejor local $\texttt{c1} \in \mathbb{R}$ que indica la importancia de la mejor solución encontrada por dicha particula, y
\item  el peso del mejor global $\texttt{c2} \in \mathbb{R}$ que establece la importancia de la mejor solución global encontrada hasta el momento.
\end{inparaenum}
Estos parámetros se encargan de dar dirección a la búsqueda de cada partícula. Adicionalmente, usualmente los valores del vector de velocidad se limitan a ciertos rangos para permitir la explotación de soluciones locales; se usa el parámetro $\texttt{vmax} \in \mathbb{R}$ para limitar la velocidad entre $[-\texttt{vmax},\texttt{vmax}]$.

A pesar de estar definido para cromosomas con representación entre los números reales, PSO puede modificarse para optimizar soluciones con representaciones variadas, definiendo apropiadamente los operadores usados para la actualización de la velocidad. Otro enfoque radica en mapear el espacio de búsqueda del problema a un dominio continuo; en el caso de soluciones con representación binaria se puede limitar la posición de las partículas entre $[0,1]$ y obtener soluciones redondeando dichos valores.
