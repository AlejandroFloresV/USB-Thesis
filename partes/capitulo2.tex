\chapter{Metaheurísticas para seleccionar instancias}
\label{capitulo2}
\lhead{Capítulo 2. \emph{Metaheurísticas para seleccionar instancias}}

\section{Metaheurísticas}

Las metaheurísticas son métodos estocásticos de búsqueda de propósito general sobre espacios combinatorios. Son usados generalmente para tratar problemas de optimización combinatoria, donde su complejidad hace imposible evaluar todas las soluciones factibles en un tiempo razonable; estos algoritmos son capaces de conseguir ``buenas'' soluciones a un problema en un período de tiempo mucho menor. Sin embargo, para muchos problemas la complejidad de estos algoritmos sigue siendo un factor prohíbitivo, debido al uso de funciones ``costosas'' para la evaluación de soluciones intermedias (\emph{fitness}).

La idea es desarrollar algoritmos que recorran solo una fracción del espacio de soluciones, y que sean capaces de encontrar soluciones óptimas o casi óptimas al problema en cuestión. Para lograrlo, las metaheurísticas combinan procesos de \emph{diversificación} e \emph{intensificación} (o \emph{exploración} y \emph{explotación} respectivamente) \cite{Yang:2008:NMA:1628847}. La fase de \emph{diversificación} implica la generación de soluciones diversas con el objeto de explorar el espacio de búsqueda, mientras que la fase de \emph{intensificación} se refiere al mejoramiento de soluciones (conseguir óptimos locales) mediante el uso de métodos de búsqueda local. La selección de las mejores soluciones asegura la convergencia a soluciones óptimas, mientras que la exploración aleatoria de soluciones evita que el algoritmo quede ``atrapado'' en óptimos locales. La combinación en el uso de ambos procesos hace posible conseguir buenas soluciones al problema sin la necesidad de recorrer el espacio de búsqueda completo.

Cada metaheurística está caracterizada por las estratégias que usa para cada fase, así como el orden y la frecuencia en que las aplica; esto permite clasificarlas en función de su similitud. En este sentido, a continuación se describe un conjunto de metaheurísticas caracterizadas por tener a la naturaleza como fuente de inspiración.

\section{Metaheurísticas inspiradas en la naturaleza}

La habilidad de la naturaleza para moldear soluciones a situaciones complejas, mediante procesos y reglas caracterizadas por su simplicidad, la ha convertido en una fuente inagorable de inspiración para el desarrollo de algoritmos de optimización. Estos algoritmos a menudo presentan buen desempeño para aproximar soluciones a todo tipo de problemas, dado que no requieren información sobre la distrubución del espacio de búsqueda. Por esta razón, existe una amplia literatura sobre enfoques bio-inspirados \cite{binitha2012survey} para resolver gran variedad de problemas en diversas áreas de computación.

En particular, los enfoques más comunes en la literatura sobre metaheurísticas inspiradas en la naturaleza se apoyan en
\begin{inparaenum}[\itshape a\upshape)]
\item la evolución de poblaciones (Algoritmos Evolutivos) y
\item el comportamiento colectivo (Inteligencia de Enjambre).
\end{inparaenum}

\subsection{Algoritmos Evolutivos}

Los Algoritmos Evolutivos (\emph{AE}) son metaheurísticas basadas en procesos de evolución biológica con el objetivo de explorar en amplitud espacios de solución con distribución desconocida. Con el fin de replicar los procesos evolutivos, los \emph{AE} mantienen un conjunto de soluciones candidatas al problema (una \emph{población} de \emph{cromosomas}/\emph{individuos}), que modifican iterativamente apoyandose en el uso de operadores de \emph{mutación}, \emph{recombinación} y/o \emph{selección}.

Los \emph{AE} codifican cada cromosoma como una cadena de genes (análogo a la estructura del ADN), donde cada gen representa una parte de la solución al problema en cuestión. A partir de esta representación, los \emph{AE} definen un conjunto de operadores que cumplen la función de las estrategias de \emph{exploración} y \emph{explotación}:

\begin{itemize}
\item \emph{Mutación}: Modifica los genes de soluciones intermedias con la finalidad de explorar el espacio de soluciones e introducir nueva información a la población. Simula la variabilidad en las poblaciones, fenómeno clave para la aparición de nuevos genes que aumenten la posibilidad de supervivencia.
\item \emph{Recombinación}/\emph{Crossover}: Permite el intercambio de información entre individuos de la población. Simula la reproducción entre individuos, necesaria para la transmisión de genes relevantes a las siguientes generaciones.
\item \emph{Selección}: Las estrategias de selección permiten definir aquellos individuos que participarán en la fase de reproducción, y por ende los genes que pasarán a la siguiente generación. Esto simula el proceso de selección natural en el que sobreviven los individuos mejor adaptados al ambiente.
\end{itemize}

En la literatura se han desarrollado diferentes esquemas que definen el uso de estos operadores. Los \emph{AE} más ``tradicionales'' son conocidos como \emph{Algoritmos Genéticos} (\emph{AG}) \cite{holland1975adaptation}, que suponen la aplicación más directa de los conceptos del proceso evolutivo. Sin embargo, dentro de la clase de \emph{AE} existe otro grupo de algoritmos que aplican dichos conceptos de forma diferente; la clase de \emph{Algorítmos de Estimación de Distribución} (``\emph{Estimation of Distribution Algorithm}'' - EDA) aplican los operadores de \emph{mutación}, \emph{recombinación} y \emph{selección} sobre una población de soluciones implicita en un modelo de distribución probabilístico.

A continuación se describen cuatro algoritmos pertenecientes a la clase de \emph{AE}: GGA, SGA y CHC, variantes del grupo de \emph{AG}, y PBIL, perteneciente a los \emph{EDA}.

\subsubsection{Generational Genetic Algorithm (GGA)}

GGA es el esquema ``tradicional'' de aplicación de los \emph{AG} \cite{back1996evolutionary,Muhlenbein91evolutionin}. Mantiene una población de individuos que evolucionan durante un número de iteraciones. Su principal característica es que en cada iteración se genera una nueva población, \emph{i.e.} un proceso de evolución \emph{generacional}.

En cada iteración el proceso evolutivo consiste en la creación de una nueva población de tamaño $\texttt{pop}$ mediante:
\begin{inparaenum}[\itshape a\upshape)]
\item la selección de los individuos para el proceso de reproducción (\emph{padres}),
\item la recombinación (con probabilidad $\texttt{cp}$) de pares de individuos \emph{padres} usando una estrategia particular de cruce/\emph{crossover}, y
\item la mutación de los individuos de la nueva población (llamados \emph{descendencia}), usando una probabilidad de mutación de cada gen igual a $\texttt{mp}$.
\end{inparaenum}
Ver el algoritmo \ref{gga-alg}.

\begin{algorithm}
\caption{Generational Genetic Algorithm}
\label{gga-alg}
\begin{algorithmic}[1]

\Require{\texttt{pop} tamaño de la población,
	\texttt{cp} probabilidad de cruce,
	\texttt{mp} probabilidad de mutación}
\Ensure{Una solución al problema}

\State $P \gets$ Generar población aleatoria de $\texttt{pop}$ individuos
\State $p^{*} \gets $ el \emph{mejor} individuo en $P$
\While{$\neg$ Condición de parada}
	\State $P' \gets \emptyset$
	\While{$\mid P' \mid < \texttt{pop}$}
		\State $p_1 \gets$ Seleccionar un individuo en $P$
		\State $p_2 \gets$ Seleccionar un individuo en $P$
		\State $c_1, c_2 \gets $ recombinar $p_1$ y $p_2$ con probabilidad $\texttt{cp}$
		\State Mutar $c_1$ y $c_2$ con probabilidad $\texttt{mp}$
		\State $P' \gets P' \cup \left\lbrace c_1, c_2 \right\rbrace$
	\EndWhile
	\State $P \gets P'$
	\If{El \emph{mejor} individuo en $P$ es \emph{mejor} que $p^{*}$}
		\State $p^{*} \gets$ el \emph{mejor} individuo en $P$
	\EndIf
\EndWhile
\State \Return $p^{*}$

\end{algorithmic}
\end{algorithm}

\subsubsection{Steady-State Genetic Algorithm (SGA)}

Descrito por \emph{Whitley et al.} \cite{whitley1988genitor}, SGA es una modificación del esquema general de \emph{AG} que sigue una estrategia reproductiva no generacional. SGA comienza con una población de tamaño $\texttt{pop}$, y en cada iteración se producen un máximo de dos nuevos individuos (no una nueva población).

En cada iteración
\begin{inparaenum}[\itshape a\upshape)]
\item se seleccionan dos individuos padres de la población actual,
\item se crea su descendencia (con probabilidad $\texttt{cp}$) mediante algún metodo de cruce/recombinación,
\item se agrega variabilidad mediante la mutación (con probabilidad $\texttt{mp}$) de la nueva descendencia, y
\item se sigue alguna estrategia de selección para reemplazar individuos en la población por la nueva descendencia, y así mantener el tamaño de la población igual a $\texttt{pop}$.
\end{inparaenum}
Ver el algoritmo \ref{sga-alg}.

\begin{algorithm}
\caption{Steady-State Genetic Algorithm}
\label{sga-alg}
\begin{algorithmic}[1]

\Require{\texttt{pop} tamaño de la población,
	\texttt{cp} probabilidad de cruce,
	\texttt{mp} probabilidad de mutación}
\Ensure{Una solución al problema}

\State $P \gets$ Generar población aleatoria de $\texttt{pop}$ individuos
\State $p^{*} \gets $ el \emph{mejor} individuo en $P$
\While{$\neg$ Condición de parada}
	\State $p_1 \gets$ Seleccionar un individuo en $P$
	\State $p_2 \gets$ Seleccionar un individuo en $P$
	\State $c_1, c_2 \gets $ recombinar $p_1$ y $p_2$ con probabilidad $\texttt{cp}$
	\State Mutar $c_1$ y $c_2$ con probabilidad $\texttt{mp}$
	\State Seguir algún criterio de reemplazo de individuos en $P$ por $c_1$ y $c_2$
	\If{El \emph{mejor} individuo en $P$ es \emph{mejor} que $p^{*}$}
		\State $p^{*} \gets$ el \emph{mejor} individuo en $P$
	\EndIf
\EndWhile
\State \Return $p^{*}$

\end{algorithmic}
\end{algorithm}

\subsubsection{CHC Adaptive Search Algorithm}

CHC se basa en el esquema de evolución generacional aplicado por GGA; mantiene una población de individuos de tamaño fijo ($\texttt{pop}$), generando una nueva población en cada iteración. Sin embargo, en cada iteración CHC aplica una estrategia de reemplazo ``elitista'', donde sobreviven los mejores $\texttt{pop}$ individuos entre la población actual y la descendencia producida.

La fase de reproducción aplicada por CHC tiene dos particularidades. En primer lugar, implementa un operador de recombinación llamado HUX, que intercambia la mitad de los genes que difieren entre los dos padres de forma aleatoria. Adicionalmente, CHC emplea ``prevención de incesto'': antes de realizar el cruce usando HUX, calcula la \emph{distancia de Hamming} entre ambos padres; si dicha distancia es mayor a cierto umbral (inicialmente $l/4$, donde $l$ es la longitud de los cromosomas), se realiza el cruce. En caso de no generarse ninguna descendencia durante una iteración particular, se disminuye el umbral en 1.

Durante el proceso de evolución de CHC no se aplica el operador de mutación: cuando el umbral de prevención de incesto llega a cero se considera que la población convergió, y comienza un proceso de repoblación en el que se usa la mejor solución encontrada hasta el momento. Se modifican hasta $35\%$ de sus genes de forma aleatoria para generar los $\texttt{pop}-1$ individuos restantes de la nueva población, y luego continuar el proceso evolutivo.

A continuación se presenta el pseudocódigo para CHC (algoritmo \ref{chc-alg}).

\begin{algorithm}
\caption{CHC Adaptive Search Algorithm}
\label{chc-alg}
\begin{algorithmic}[1]

\Require \texttt{pop} tamaño de la población
\Ensure Una solución al problema

\State $P \gets$ Generar población aleatoria de $\texttt{pop}$ individuos
\State $p^{*} \gets $ el \emph{mejor} individuo en $P$
\State $\mu \gets l/4$ \Comment Umbral de cruce
\While {$\neg$ Condición de parada}
	\For {$i \in [1 \dots \texttt{pop}/2]$}
		\State $p_1 \gets$ Seleccionar un individuo en $P$
		\State $p_2 \gets$ Seleccionar un individuo en $P$
		\If {$hamming(p_1,p_2) > \mu$}
			\State $c_1, c_2 \gets $ recombinar $p_1$ y $p_2$ usando HUX
			\State $P \gets P \cup \left\lbrace c_1, c_2 \right\rbrace$
		\EndIf
	\EndFor
	\If {$\mid P \mid = \texttt{pop}$}
		\State $\mu \gets \mu-1$
		\If {$\mu = 0$}
			\State $P \gets$ Generar población de $\texttt{pop}$ individuos usando $p^*$
			\State $\mu \gets l/4$
		\EndIf
	\Else
		\State $P \gets \texttt{pop}$ mejores individuos en $P$
		\If {El \emph{mejor} individuo en $P$ es \emph{mejor} que $p^{*}$}
			\State $p^{*} \gets$ el \emph{mejor} individuo en $P$
		\EndIf
	\EndIf
\EndWhile
\State \Return $p^{*}$

\end{algorithmic}
\end{algorithm}

\subsubsection{Population-Based Incremental Learning (PBIL)}

Esta metaheurística consiste en mantener un vector de probabilidades $V_p$ de tamaño $L$ (número de instancias iniciales), donde $V_p\left[i\right]$ es la probabilidad de que la $i$-esima instancia pertenezca a la solución ($i$-esimo bit sea 1).\\
Inicialmente $V_p\left[i\right] = 0.5\ \ \forall{i \in [1\dots L]}$. En cada iteración se sigue el siguiente proceso:

\begin{enumerate}[a)]
\item Se generan $N$ cromosomas (secuencias de bits) basados en las probabilidades en $V_p$.
\item Se acerca $V_p$ hacia la mejor solución generada $S_{best}$
$$V_p\left[i\right]=V_p\left[i\right]*(1-LR)+S_{best}\left[i\right]*LR$$
Donde $LR$ es la tasa de aprendizaje (\emph{learning rate}).
\item Se aleja $V_p$ de la peor solución generada $S_{worst}$\\
\noindent{Si $S_{best}\left[i\right] <> S_{worst}\left[i\right]$}
$$V_p\left[i\right]=V_p\left[i\right]*(1-Negat\_LR)+S_{best}\left[i\right]*Negat\_LR$$
Donde $Negat\_LR$ es la tasa de aprendizaje negativa.
\end{enumerate}

\begin{algorithm}
\caption{Population-Based Incremental Learning}
\label{pbil-alg}
\begin{algorithmic}[1]

\Require \texttt{pop} tamaño de la población,
	\texttt{mp} probabilidad de mutación,
	\texttt{ms} mutation shift,
	\texttt{lr} learning rate,
	\texttt{nlr} negative learning rate
\Ensure Una solución al problema

\State $V \gets$ Vector de probabilidades de tamaño $l$
\State $p^* \gets$ Una solución cualquiera
\While {$\neg$ Condición de parada}
	\State $P \gets$ Generar población de tamaño $\texttt{pop}$ según las probabilidades en $V$
	\State $b \gets $ El \emph{mejor} individuo en $P$
	\State $w \gets $ El \emph{peor} individuo en $P$
	\If {$b$ es \emph{mejor} que $p^{*}$}
		\State $p^{*} \gets b$
	\EndIf
	\For {$i \in [1 \dots l]$} \Comment{Actualizar el vector de probabilidades}
		\State $V_i \gets V_i * (1 - \texttt{lr}) + b_i * \texttt{lr}$
		\If {$b_i \neq w_i$}
			\State $V_i \gets V_i * (1 - \texttt{nlr}) + b_i * \texttt{nlr}$
		\EndIf
		\If {$\mathrm{Unif}(0,1) < \texttt{mp}$} \Comment{Mutación con probabilidad $\texttt{mp}$}
			\State $V_i \gets V_i * (1 - \texttt{ms}) + \mathrm{UnifDiscreta}(0,1) * \texttt{ms}$
		\EndIf
	\EndFor
\EndWhile
\State \Return $p^{*}$

\end{algorithmic}
\end{algorithm}

\subsection{Inteligencia de Enjambre}

\subsubsection{Particle Swarm Optimization (PSO)}

\emph{PSO} se inspira en el comportamiento de organismos biológicos, en particular, del vuelo de una bandada de aves. Cada ave o ``partícula'' (que representa una posible solución del espacio de búsqueda) tiene una velocidad asociada, y modifica su vuelo en relación a su propia experiencia, y a la experiencia de sus ``compañeras''. Diferentes estudios muestran que \emph{PSO} obtiene mejores resultados que los algoritmos genéticos (\emph{GA}), y en menor tiempo de cómputo.

Inicialmente se obtienen $P$ soluciones aleatorias, o partículas. Cada partícula $i$ está representada por un posición en un espacio $s$-dimensional \linebreak $\textbf{x}_i =\ <x_{i1},x_{i2},\dots,x_{is}>$. Luego, se realizan un número de iteraciones (\texttt{MAX\_ITER}) en las que se actualiza la posición de cada partícula de acuerdo a su velocidad $v_i$:

$$\textbf{x}_i = \textbf{x}_i + v_i$$

$$v_i = w v_i + c_1 Rand() (p_i - \textbf{x}_i) +  c_2 Rand() (p_g - \textbf{x}_i)$$

Donde $c_1$ y $c_2$ con constantes, $Rand()$ es una función aleatoria $[0,1]$, $p_i$ es la mejor solución encontrada por la partícula $i$ (de acuerdo a una función de evaluación/\emph{fitness} establecida), $p_g$ es la mejor solución global, y $w$ es el ``peso de inercia'' que establece la posible variabilidad de $v_i$. $w$ disminuye cada iteración de acuerdo a la siguiente fórmula:

$$w = \frac{(w_{start} - w_{end})(\texttt{MAX\_ITER} - \texttt{Iter})}{\texttt{MAX\_ITER} + w_{end}}$$

Siendo \texttt{Iter} la iteración actual del algoritmo, y $w_{start}$ y $w_{end}$ valores predeterminados.

\section{Adaptación para el problema de Selección de Instancias}

\subsection{Representación}

\subsection{Función objetivo}
